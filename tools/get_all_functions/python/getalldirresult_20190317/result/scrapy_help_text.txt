Help on package scrapy:

NAME
    scrapy - Scrapy - a web crawling and web scraping framework written for Python

PACKAGE CONTENTS
    __main__
    _monkeypatches
    cmdline
    command
    commands (package)
    conf
    contracts (package)
    contrib (package)
    contrib_exp (package)
    core (package)
    crawler
    downloadermiddlewares (package)
    dupefilter
    dupefilters
    exceptions
    exporters
    extension
    extensions (package)
    http (package)
    interfaces
    item
    link
    linkextractor
    linkextractors (package)
    loader (package)
    log
    logformatter
    mail
    middleware
    pipelines (package)
    project
    resolver
    responsetypes
    selector (package)
    settings (package)
    shell
    signalmanager
    signals
    spider
    spiderloader
    spidermanager
    spidermiddlewares (package)
    spiders (package)
    squeue
    squeues
    stats
    statscol
    statscollectors
    telnet
    utils (package)
    xlib (package)

CLASSES
    builtins.dict(builtins.object)
        scrapy.item.Field
    parsel.selector.Selector(builtins.object)
        scrapy.selector.unified.Selector(parsel.selector.Selector, scrapy.utils.trackref.object_ref)
    scrapy.item.DictItem(collections.abc.MutableMapping, scrapy.item.BaseItem)
        scrapy.item.Item
    scrapy.utils.trackref.object_ref(builtins.object)
        scrapy.http.request.Request
            scrapy.http.request.form.FormRequest
        scrapy.selector.unified.Selector(parsel.selector.Selector, scrapy.utils.trackref.object_ref)
        scrapy.spiders.Spider
    
    class Field(builtins.dict)
     |  Container of field metadata
     |  
     |  Method resolution order:
     |      Field
     |      builtins.dict
     |      builtins.object
     |  
     |  Data descriptors defined here:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.dict:
     |  
     |  __contains__(self, key, /)
     |      True if D has a key k, else False.
     |  
     |  __delitem__(self, key, /)
     |      Delete self[key].
     |  
     |  __eq__(self, value, /)
     |      Return self==value.
     |  
     |  __ge__(self, value, /)
     |      Return self>=value.
     |  
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |  
     |  __getitem__(...)
     |      x.__getitem__(y) <==> x[y]
     |  
     |  __gt__(self, value, /)
     |      Return self>value.
     |  
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  __iter__(self, /)
     |      Implement iter(self).
     |  
     |  __le__(self, value, /)
     |      Return self<=value.
     |  
     |  __len__(self, /)
     |      Return len(self).
     |  
     |  __lt__(self, value, /)
     |      Return self<value.
     |  
     |  __ne__(self, value, /)
     |      Return self!=value.
     |  
     |  __new__(*args, **kwargs) from builtins.type
     |      Create and return a new object.  See help(type) for accurate signature.
     |  
     |  __repr__(self, /)
     |      Return repr(self).
     |  
     |  __setitem__(self, key, value, /)
     |      Set self[key] to value.
     |  
     |  __sizeof__(...)
     |      D.__sizeof__() -> size of D in memory, in bytes
     |  
     |  clear(...)
     |      D.clear() -> None.  Remove all items from D.
     |  
     |  copy(...)
     |      D.copy() -> a shallow copy of D
     |  
     |  fromkeys(iterable, value=None, /) from builtins.type
     |      Returns a new dict with keys from iterable and values equal to value.
     |  
     |  get(...)
     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
     |  
     |  items(...)
     |      D.items() -> a set-like object providing a view on D's items
     |  
     |  keys(...)
     |      D.keys() -> a set-like object providing a view on D's keys
     |  
     |  pop(...)
     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
     |      If key is not found, d is returned if given, otherwise KeyError is raised
     |  
     |  popitem(...)
     |      D.popitem() -> (k, v), remove and return some (key, value) pair as a
     |      2-tuple; but raise KeyError if D is empty.
     |  
     |  setdefault(...)
     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
     |  
     |  update(...)
     |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.
     |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]
     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v
     |      In either case, this is followed by: for k in F:  D[k] = F[k]
     |  
     |  values(...)
     |      D.values() -> an object providing a view on D's values
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from builtins.dict:
     |  
     |  __hash__ = None
    
    class FormRequest(scrapy.http.request.Request)
     |  Inherit from this class (instead of object) to a keep a record of live
     |  instances
     |  
     |  Method resolution order:
     |      FormRequest
     |      scrapy.http.request.Request
     |      scrapy.utils.trackref.object_ref
     |      builtins.object
     |  
     |  Methods defined here:
     |  
     |  __init__(self, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |  
     |  from_response(response, formname=None, formid=None, formnumber=0, formdata=None, clickdata=None, dont_click=False, formxpath=None, formcss=None, **kwargs) from builtins.type
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from scrapy.http.request.Request:
     |  
     |  __repr__ = __str__(self)
     |  
     |  __str__(self)
     |      Return str(self).
     |  
     |  copy(self)
     |      Return a copy of this Request
     |  
     |  replace(self, *args, **kwargs)
     |      Create a new Request with the same attributes except for those
     |      given new values.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from scrapy.http.request.Request:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  body
     |  
     |  encoding
     |  
     |  meta
     |  
     |  url
     |  
     |  ----------------------------------------------------------------------
     |  Static methods inherited from scrapy.utils.trackref.object_ref:
     |  
     |  __new__(cls, *args, **kwargs)
     |      Create and return a new object.  See help(type) for accurate signature.
    
    class Item(DictItem)
     |  Base class for all scraped items.
     |  
     |  Method resolution order:
     |      Item
     |      DictItem
     |      collections.abc.MutableMapping
     |      collections.abc.Mapping
     |      collections.abc.Collection
     |      collections.abc.Sized
     |      collections.abc.Iterable
     |      collections.abc.Container
     |      BaseItem
     |      scrapy.utils.trackref.object_ref
     |      builtins.object
     |  
     |  Data and other attributes defined here:
     |  
     |  __abstractmethods__ = frozenset()
     |  
     |  fields = {}
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from DictItem:
     |  
     |  __delitem__(self, key)
     |  
     |  __getattr__(self, name)
     |  
     |  __getitem__(self, key)
     |  
     |  __hash__(self, /)
     |      Return hash(self).
     |  
     |  __init__(self, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  __iter__(self)
     |  
     |  __len__(self)
     |  
     |  __repr__(self)
     |      Return repr(self).
     |  
     |  __setattr__(self, name, value)
     |      Implement setattr(self, name, value).
     |  
     |  __setitem__(self, key, value)
     |  
     |  copy(self)
     |  
     |  keys(self)
     |      D.keys() -> a set-like object providing a view on D's keys
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from DictItem:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from collections.abc.MutableMapping:
     |  
     |  clear(self)
     |      D.clear() -> None.  Remove all items from D.
     |  
     |  pop(self, key, default=<object object at 0x109894050>)
     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
     |      If key is not found, d is returned if given, otherwise KeyError is raised.
     |  
     |  popitem(self)
     |      D.popitem() -> (k, v), remove and return some (key, value) pair
     |      as a 2-tuple; but raise KeyError if D is empty.
     |  
     |  setdefault(self, key, default=None)
     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
     |  
     |  update(*args, **kwds)
     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
     |      In either case, this is followed by: for k, v in F.items(): D[k] = v
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from collections.abc.Mapping:
     |  
     |  __contains__(self, key)
     |  
     |  __eq__(self, other)
     |      Return self==value.
     |  
     |  get(self, key, default=None)
     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.
     |  
     |  items(self)
     |      D.items() -> a set-like object providing a view on D's items
     |  
     |  values(self)
     |      D.values() -> an object providing a view on D's values
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from collections.abc.Mapping:
     |  
     |  __reversed__ = None
     |  
     |  ----------------------------------------------------------------------
     |  Class methods inherited from collections.abc.Collection:
     |  
     |  __subclasshook__(C) from scrapy.item.ItemMeta
     |      Abstract classes can override this to customize issubclass().
     |      
     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().
     |      It should return True, False or NotImplemented.  If it returns
     |      NotImplemented, the normal algorithm is used.  Otherwise, it
     |      overrides the normal algorithm (and the outcome is cached).
     |  
     |  ----------------------------------------------------------------------
     |  Static methods inherited from scrapy.utils.trackref.object_ref:
     |  
     |  __new__(cls, *args, **kwargs)
     |      Create and return a new object.  See help(type) for accurate signature.
    
    class Request(scrapy.utils.trackref.object_ref)
     |  Inherit from this class (instead of object) to a keep a record of live
     |  instances
     |  
     |  Method resolution order:
     |      Request
     |      scrapy.utils.trackref.object_ref
     |      builtins.object
     |  
     |  Methods defined here:
     |  
     |  __init__(self, url, callback=None, method='GET', headers=None, body=None, cookies=None, meta=None, encoding='utf-8', priority=0, dont_filter=False, errback=None, flags=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  __repr__ = __str__(self)
     |  
     |  __str__(self)
     |      Return str(self).
     |  
     |  copy(self)
     |      Return a copy of this Request
     |  
     |  replace(self, *args, **kwargs)
     |      Create a new Request with the same attributes except for those
     |      given new values.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  body
     |  
     |  encoding
     |  
     |  meta
     |  
     |  url
     |  
     |  ----------------------------------------------------------------------
     |  Static methods inherited from scrapy.utils.trackref.object_ref:
     |  
     |  __new__(cls, *args, **kwargs)
     |      Create and return a new object.  See help(type) for accurate signature.
    
    class Selector(parsel.selector.Selector, scrapy.utils.trackref.object_ref)
     |  :class:`Selector` allows you to select parts of an XML or HTML text using CSS
     |  or XPath expressions and extract data from it.
     |  
     |  ``text`` is a ``unicode`` object in Python 2 or a ``str`` object in Python 3
     |  
     |  ``type`` defines the selector type, it can be ``"html"``, ``"xml"`` or ``None`` (default).
     |  If ``type`` is ``None``, the selector defaults to ``"html"``.
     |  
     |  Method resolution order:
     |      Selector
     |      parsel.selector.Selector
     |      scrapy.utils.trackref.object_ref
     |      builtins.object
     |  
     |  Methods defined here:
     |  
     |  __init__(self, response=None, text=None, type=None, root=None, _root=None, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  extract_unquoted(self)
     |  
     |  select(self, xpath)
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  response
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |  
     |  selectorlist_cls = <class 'scrapy.selector.unified.SelectorList'>
     |      The :class:`SelectorList` class is a subclass of the builtin ``list``
     |      class, which provides a few additional methods.
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from parsel.selector.Selector:
     |  
     |  __bool__(self)
     |      Return ``True`` if there is any real content selected or ``False``
     |      otherwise.  In other words, the boolean value of a :class:`Selector` is
     |      given by the contents it selects.
     |  
     |  __getstate__(self)
     |  
     |  __nonzero__ = __bool__(self)
     |  
     |  __repr__ = __str__(self)
     |  
     |  __str__(self)
     |      Return str(self).
     |  
     |  css(self, query)
     |      Apply the given CSS selector and return a :class:`SelectorList` instance.
     |      
     |      ``query`` is a string containing the CSS selector to apply.
     |      
     |      In the background, CSS queries are translated into XPath queries using
     |      `cssselect`_ library and run ``.xpath()`` method.
     |  
     |  extract = get(self)
     |  
     |  get(self)
     |      Serialize and return the matched nodes in a single unicode string.
     |      Percent encoded content is unquoted.
     |  
     |  getall(self)
     |      Serialize and return the matched node in a 1-element list of unicode strings.
     |  
     |  re(self, regex, replace_entities=True)
     |      Apply the given regex and return a list of unicode strings with the
     |      matches.
     |      
     |      ``regex`` can be either a compiled regular expression or a string which
     |      will be compiled to a regular expression using ``re.compile(regex)``.
     |      
     |      By default, character entity references are replaced by their
     |      corresponding character (except for ``&amp;`` and ``&lt;``.
     |      Passing ``replace_entities`` as ``False`` switches off these
     |      replacements.
     |  
     |  re_first(self, regex, default=None, replace_entities=True)
     |      Apply the given regex and return the first unicode string which
     |      matches. If there is no match, return the default value (``None`` if
     |      the argument is not provided).
     |      
     |      By default, character entity references are replaced by their
     |      corresponding character (except for ``&amp;`` and ``&lt;``.
     |      Passing ``replace_entities`` as ``False`` switches off these
     |      replacements.
     |  
     |  register_namespace(self, prefix, uri)
     |      Register the given namespace to be used in this :class:`Selector`.
     |      Without registering namespaces you can't select or extract data from
     |      non-standard namespaces. See :ref:`selector-examples-xml`.
     |  
     |  remove_namespaces(self)
     |      Remove all namespaces, allowing to traverse the document using
     |      namespace-less xpaths. See :ref:`removing-namespaces`.
     |  
     |  xpath(self, query, namespaces=None, **kwargs)
     |      Find nodes matching the xpath ``query`` and return the result as a
     |      :class:`SelectorList` instance with all elements flattened. List
     |      elements implement :class:`Selector` interface too.
     |      
     |      ``query`` is a string containing the XPATH query to apply.
     |      
     |      ``namespaces`` is an optional ``prefix: namespace-uri`` mapping (dict)
     |      for additional prefixes to those registered with ``register_namespace(prefix, uri)``.
     |      Contrary to ``register_namespace()``, these prefixes are not
     |      saved for future calls.
     |      
     |      Any additional named arguments can be used to pass values for XPath
     |      variables in the XPath expression, e.g.::
     |      
     |          selector.xpath('//a[href=$url]', url="http://www.example.com")
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from parsel.selector.Selector:
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  attrib
     |      Return the attributes dictionary for underlying element.
     |  
     |  namespaces
     |  
     |  root
     |  
     |  text
     |  
     |  type
     |  
     |  ----------------------------------------------------------------------
     |  Static methods inherited from scrapy.utils.trackref.object_ref:
     |  
     |  __new__(cls, *args, **kwargs)
     |      Create and return a new object.  See help(type) for accurate signature.
    
    class Spider(scrapy.utils.trackref.object_ref)
     |  Base class for scrapy spiders. All spiders must inherit from this
     |  class.
     |  
     |  Method resolution order:
     |      Spider
     |      scrapy.utils.trackref.object_ref
     |      builtins.object
     |  
     |  Methods defined here:
     |  
     |  __init__(self, name=None, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  __repr__ = __str__(self)
     |  
     |  __str__(self)
     |      Return str(self).
     |  
     |  log(self, message, level=10, **kw)
     |      Log the given message at the given log level
     |      
     |      This helper wraps a log call to the logger within the spider, but you
     |      can use it directly (e.g. Spider.logger.info('msg')) or use any other
     |      Python logger too.
     |  
     |  make_requests_from_url(self, url)
     |      This method is deprecated.
     |  
     |  parse(self, response)
     |  
     |  set_crawler(self, crawler)
     |  
     |  start_requests(self)
     |  
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |  
     |  from_crawler(crawler, *args, **kwargs) from builtins.type
     |  
     |  handles_request(request) from builtins.type
     |  
     |  update_settings(settings) from builtins.type
     |  
     |  ----------------------------------------------------------------------
     |  Static methods defined here:
     |  
     |  close(spider, reason)
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  logger
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |  
     |  custom_settings = None
     |  
     |  name = None
     |  
     |  ----------------------------------------------------------------------
     |  Static methods inherited from scrapy.utils.trackref.object_ref:
     |  
     |  __new__(cls, *args, **kwargs)
     |      Create and return a new object.  See help(type) for accurate signature.

DATA
    __all__ = ['__version__', 'version_info', 'twisted_version', 'Spider',...
    twisted_version = (18, 7, 0)
    version_info = (1, 5, 1)

VERSION
    1.5.1

FILE
    /Users/jack/miniconda2/envs/py37/lib/python3.6/site-packages/scrapy/__init__.py


